{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "settled-sussex",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique customers: 4577\n",
      "Number of rows in the DataFrame: 1967994\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from scipy import sparse\n",
    "import random\n",
    "import lightfm \n",
    "from lightfm import LightFM, cross_validation\n",
    "from lightfm.evaluation import precision_at_k, recall_at_k, auc_score, reciprocal_rank\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# inspired by https://www.kaggle.com/code/pegahpooya/spotify-playlists-recommender-system/notebook\n",
    "\n",
    "#p = 1.0 \n",
    "df = pd.read_csv('purchase_history_anonymized.csv', sep=',', error_bad_lines=False, warn_bad_lines=False) #, skiprows=lambda i: i>0 and random.random() > p)\n",
    "df = df.groupby('product_L2').filter(lambda x : len(x)>=30)\n",
    "df = df[df.groupby('customer').product_L2.transform('nunique') >= 10] # 10 interactions with unique products\n",
    "customer_counts = df.groupby('customer')['product_L2'].count()\n",
    "customers_with_20_or_more_products = customer_counts[customer_counts >= 20].index # 20 interactions in total\n",
    "df = df[df['customer'].isin(customers_with_20_or_more_products)]\n",
    "\n",
    "customer_id = 'cust-00008'\n",
    "customer_interactions = df[df['customer'] == customer_id]\n",
    "last_5_interactions = customer_interactions.drop_duplicates(subset='product_L2', keep='last').tail(5)\n",
    "product_ids = last_5_interactions['product_L2'].tolist()\n",
    "df_siemens = df[~((df['customer'] == customer_id) & (df['product_L2'].isin(product_ids)))]\n",
    "\n",
    "size = lambda x: len(x)\n",
    "df_freq = df_siemens.groupby(['customer', 'product_L2']).agg('size').reset_index().rename(columns={0:'freq'})[['customer', 'product_L2', 'freq']].sort_values(['freq'], ascending=False)\n",
    "\n",
    "df_productL2 = pd.DataFrame(df_freq[\"product_L2\"].unique())\n",
    "df_productL2 = df_productL2.reset_index()\n",
    "df_productL2 = df_productL2.rename(columns={'index':'product_L2_id', 0:'product_L2'})\n",
    "\n",
    "df_freq  = pd.merge(df_freq , df_productL2, how='inner', on='product_L2')\n",
    "\n",
    "unique_customers = df['customer'].nunique()\n",
    "number_of_rows = df.shape[0]\n",
    "print(f\"unique customers: {unique_customers}\")\n",
    "print(f\"Number of rows in the DataFrame: {number_of_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "comparative-journalism",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interaction_matrix(df,user_col, item_col, rating_col, norm= False, threshold = None):\n",
    "    interactions = df.groupby([user_col, item_col])[rating_col] \\\n",
    "            .sum().unstack().reset_index(). \\\n",
    "            fillna(0).set_index(user_col)\n",
    "    if norm:\n",
    "        interactions = interactions.applymap(lambda x: 1 if x > threshold else 0)\n",
    "    return interactions\n",
    "\n",
    "def create_user_dict(interactions):\n",
    "    customer = list(interactions.index)\n",
    "    user_dict = {}\n",
    "    counter = 0 \n",
    "    for i in customer:\n",
    "        user_dict[i] = counter\n",
    "        counter += 1\n",
    "    return user_dict\n",
    "\n",
    "def create_item_dict(df,id_col,name_col):\n",
    "    item_dict ={}\n",
    "    for i in range(df.shape[0]):\n",
    "        item_dict[(df.loc[i,id_col])] = df.loc[i,name_col]\n",
    "    return item_dict\n",
    "\n",
    "\n",
    "def accuracy_at_k(model, interactions, k):\n",
    "\n",
    "    interactions_dense = interactions.toarray()\n",
    "    predictions = model.predict_rank(interactions)\n",
    "    predictions_dense = predictions.toarray()\n",
    "    relevant = interactions_dense > 0\n",
    "    selected = predictions_dense < k\n",
    "    accuracy_per_user = np.mean(np.logical_or(np.logical_not(relevant), selected), axis=1)\n",
    "\n",
    "    return np.mean(accuracy_per_user)\n",
    "\n",
    "\n",
    "def runMF(interactions, n_components=700, loss='warp-kos', k=15, epoch=30,n_jobs = 4, max_sampled= 3): #n_components can be change for better performance   \n",
    "    model = LightFM(no_components= n_components, loss=loss,k=k, max_sampled=max_sampled)\n",
    "    model.fit(x,epochs=epoch,num_threads = n_jobs)\n",
    "    return model\n",
    "\n",
    "def sample_recommendation_user(model, interactions, customer, user_dict, item_dict,threshold = 0,nrec_items = 10, show = True):\n",
    "    n_users, n_items = interactions.shape\n",
    "    user_x = user_dict[customer]\n",
    "    scores = pd.Series(model.predict(user_x,np.arange(n_items)))\n",
    "    scores.index = interactions.columns\n",
    "    scores = list(pd.Series(scores.sort_values(ascending=False).index))\n",
    "    \n",
    "    known_items = list(pd.Series(interactions.loc[customer,:] \\\n",
    "                                 [interactions.loc[customer,:] > threshold].index) \\\n",
    "\t\t\t\t\t\t\t\t .sort_values(ascending=False))\n",
    "    \n",
    "    scores = [x for x in scores if x not in known_items]\n",
    "    return_score_list = scores[0:nrec_items]\n",
    "    known_items = list(pd.Series(known_items).apply(lambda x: item_dict[x]))\n",
    "    scores = list(pd.Series(return_score_list).apply(lambda x: item_dict[x]))\n",
    "    if show == True:\n",
    "        print(\"Known Likes:\")\n",
    "        counter = 1\n",
    "        for i in known_items:\n",
    "            print(str(counter) + '- ' + i)\n",
    "            counter+=1\n",
    "\n",
    "        print(\"\\n Recommended Items:\")\n",
    "        counter = 1\n",
    "        for i in scores:\n",
    "            print(str(counter) + '- ' + i)\n",
    "            counter+=1\n",
    "    return return_score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "radical-economics",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = create_interaction_matrix(df = df_freq, user_col = \"customer\", item_col = 'product_L2_id', rating_col = 'freq', norm= False, threshold = None)\n",
    "interactions.head()\n",
    "user_dict = create_user_dict(interactions=interactions)\n",
    "product_L2s_dict = create_item_dict(df = df_productL2, id_col = 'product_L2_id', name_col = 'product_L2')\n",
    "\n",
    "x = sparse.csr_matrix(interactions.values)\n",
    "train, test = lightfm.cross_validation.random_train_test_split(x, test_percentage=0.3, random_state=None)\n",
    "model = runMF(interactions = train, n_components = 700, loss = 'warp-kos', k = 15, epoch = 30, n_jobs = 4, max_sampled=3)\n",
    "train_auc = auc_score(model, train, num_threads=4).mean()\n",
    "test_auc = auc_score(model, test, train_interactions=train, num_threads=4).mean()\n",
    "train_precision = precision_at_k(model, train, k=10).mean()\n",
    "test_precision_at_10 = precision_at_k(model, test, k=10, train_interactions=train).mean()\n",
    "test_precision_at_5 = precision_at_k(model, test, k=5, train_interactions=train).mean()\n",
    "test_recall = recall_at_k(model, test, k=10, train_interactions=train).mean()\n",
    "test_recall_at_20 = recall_at_k(model, test, k=20, train_interactions=train).mean()\n",
    "test_recall_at_40= recall_at_k(model, test, k=40, train_interactions=train).mean()\n",
    "test_reciprocal = reciprocal_rank(model, test, train_interactions=train, num_threads=4).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "twelve-character",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC: 0.9999406\n",
      "Test Reciprocal: 0.996\n",
      "Test Precision at 10 0.804\n",
      "Test Precision at 5 0.938\n",
      "Test Recall at 10 0.752\n",
      "Test Recall at 20 0.910\n"
     ]
    }
   ],
   "source": [
    "print('Test AUC: %.7f' % (test_auc))\n",
    "print('Test Reciprocal: %.3f' % (test_reciprocal))\n",
    "print('Test Precision at 10 %.3f' % (test_precision_at_10))\n",
    "print('Test Precision at 5 %.3f' % (test_precision_at_5))\n",
    "print('Test Recall at 10 %.3f' % (test_recall))\n",
    "print('Test Recall at 20 %.3f' % (test_recall_at_20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-transfer",
   "metadata": {},
   "source": [
    "## Metric: Precision at k\n",
    "##### k = 10 \n",
    "Out of k recommended items, the user interacted with x items â€“ we will treat this as a binary signal of relevance. In this case, the Avg Precision at 10 is 80,4%. Out of 10 recommendations, more than 8 were good ones. The system is doing a decent job. \n",
    "##### k = 5\n",
    "In this case, the Avg Precision at 5 is 93,8%. Out of 5 recommendations, the avg is almost 5. We can  definitely say that the first 5 recommendations look very promising. \n",
    "\n",
    "## Metric: Recall at k\n",
    "Imagine you have a list of top k recommendations, and there are a total of 30 items in the dataset that are actually relevant (only an assumption). If the system includes 9 relevant items in the top 10, the Recall at 10 is 30% (9 out of 30).\n",
    "\n",
    "## Metric: Reciprocal ranking\n",
    "Mean Reciprocal Rank (MRR) is a ranking quality metric. It considers the position of the first relevant item in the ranked list. A Reciprocal Rank is the inverse of the position of the first relevant item. If the first relevant item is in position 2, the reciprocal rank is 1/2. If we think of recommendations for 6 users with the following example values: \n",
    "- For user 1, the first relevant item is in position 1, so the RR is 1. \n",
    "- For user 2,4,6, the first relevant item is in position 3, so the RR is 1/3 â‰ˆ 0.33. \n",
    "- For user 3, the first relevant item is in position 2, so the RR is 1/2 = 0,5. \n",
    "- For user 5, the first relevant item is in position 4, so the RR is 1/4 = 0.25. \n",
    "#### Overall: MRR = (1 + 0,33 + 0,5 + 0,33 + 0,25 + 0,33) = 2,74/6 = 0,456\n",
    "\n",
    "####  The system gets a Reciprocal Ranking of 0.996 \n",
    "This indicates that the first relevant item is almost everytime the first recommended products overall, which is very pleasant result.\n",
    "\n",
    "- AUC             => 0.999\n",
    "- Precision at 10 => 80,4% of the top 10 are relevant items\n",
    "- Precision at 5  => 93,8% of the top 5 are relevant items\n",
    "- Recall at 10    => 75,2% of all relevant items are in the top 10 \n",
    "- Recall at 20    => 91,0% of all relevant items are in the top 20 \n",
    "\n",
    "Those are decent numbers for arecommender system, which shows a overall good performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-botswana",
   "metadata": {},
   "source": [
    "### Another evaluation technique - Hitrate for a single user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "opposite-turkey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  country    customer industry product_L1  product_L2  \\\n",
      "2023995  1490  land-12  cust-00008   ind-42  prdL1-063  prdL2-1339   \n",
      "2024153  1490  land-12  cust-00008   ind-42  prdL1-068  prdL2-1543   \n",
      "2031265  1497  land-12  cust-00008   ind-42  prdL1-060  prdL2-1131   \n",
      "2032669  1497  land-12  cust-00008   ind-42  prdL1-063  prdL2-1344   \n",
      "2033793  1498  land-12  cust-00008   ind-42  prdL1-061  prdL2-1158   \n",
      "\n",
      "          product_L3  price_rescaled  \n",
      "2023995  prdL3-25218             302  \n",
      "2024153  prdL3-30015            2552  \n",
      "2031265  prdL3-23728             145  \n",
      "2032669  prdL3-25245            1165  \n",
      "2033793  prdL3-23814              40  \n"
     ]
    }
   ],
   "source": [
    "print(last_5_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "mighty-calcium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known Likes:\n",
      "1- prdL2-1184\n",
      "2- prdL2-1182\n",
      "3- prdL2-1155\n",
      "4- prdL2-2108\n",
      "5- prdL2-1598\n",
      "6- prdL2-1822\n",
      "7- prdL2-1620\n",
      "8- prdL2-1014\n",
      "9- prdL2-0916\n",
      "10- prdL2-1427\n",
      "11- prdL2-0960\n",
      "12- prdL2-1263\n",
      "13- prdL2-1700\n",
      "14- prdL2-1599\n",
      "15- prdL2-1837\n",
      "16- prdL2-1245\n",
      "17- prdL2-1180\n",
      "18- prdL2-1336\n",
      "19- prdL2-1160\n",
      "20- prdL2-1574\n",
      "21- prdL2-1159\n",
      "22- prdL2-1329\n",
      "23- prdL2-1830\n",
      "24- prdL2-1178\n",
      "25- prdL2-1334\n",
      "26- prdL2-1823\n",
      "27- prdL2-1134\n",
      "28- prdL2-1276\n",
      "29- prdL2-1836\n",
      "30- prdL2-1170\n",
      "31- prdL2-1592\n",
      "32- prdL2-1345\n",
      "33- prdL2-1223\n",
      "34- prdL2-1235\n",
      "35- prdL2-0964\n",
      "36- prdL2-1358\n",
      "37- prdL2-1332\n",
      "38- prdL2-1835\n",
      "39- prdL2-1219\n",
      "40- prdL2-1762\n",
      "41- prdL2-1839\n",
      "42- prdL2-1794\n",
      "43- prdL2-1244\n",
      "44- prdL2-1238\n",
      "45- prdL2-1239\n",
      "46- prdL2-1340\n",
      "47- prdL2-1356\n",
      "48- prdL2-1396\n",
      "49- prdL2-1240\n",
      "50- prdL2-1208\n",
      "51- prdL2-0911\n",
      "52- prdL2-1234\n",
      "53- prdL2-1423\n",
      "54- prdL2-1221\n",
      "55- prdL2-1243\n",
      "56- prdL2-1587\n",
      "57- prdL2-1428\n",
      "58- prdL2-1201\n",
      "59- prdL2-0194\n",
      "60- prdL2-1547\n",
      "61- prdL2-0912\n",
      "62- prdL2-1202\n",
      "63- prdL2-1204\n",
      "64- prdL2-1132\n",
      "65- prdL2-0195\n",
      "66- prdL2-1825\n",
      "67- prdL2-1228\n",
      "\n",
      " Recommended Items:\n",
      "1- prdL2-1339\n",
      "2- prdL2-1233\n",
      "3- prdL2-1593\n",
      "4- prdL2-1206\n",
      "5- prdL2-1344\n"
     ]
    }
   ],
   "source": [
    "# generating recommendations\n",
    "rec_list = sample_recommendation_user(model = model, \n",
    "                                      interactions = interactions, \n",
    "                                      customer = 'cust-00008', \n",
    "                                      user_dict = user_dict,\n",
    "                                      item_dict = product_L2s_dict, \n",
    "                                      threshold = 0,\n",
    "                                      nrec_items = 5,\n",
    "                                      show = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appointed-freeze",
   "metadata": {},
   "source": [
    "### 2/5 are in the Top 5: L2-1339 (Top 1), L2-1344 (Top 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "logical-pressure",
   "metadata": {},
   "source": [
    "### the deleted interactions, claims 2 top 5 spots\n",
    "The interactions were deleted before training the model, so that the model treats these products as if they had never been purchased before. This looks pretty promising, especially because 2 of the 5 deleted items, claims a top 5 spot "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patient-costa",
   "metadata": {},
   "source": [
    "### Item-Item Recommendations\n",
    "LightFM is primarily designed for user-item interactions, i.e. it focuses on predicting interactions between users and items based on previous interactions. To obtain item-item collaboration recommendations, we need to generate recommendations that match a specific item. We can analyse the relationships between items based on user interactions. This can be achieved by looking at which items are often purchased together or consumed by the same users. This approach is often referred to as \"co-operative filtering\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "functional-bradford",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended items for this purchase: ['prdL2-1228', 'prdL2-1204', 'prdL2-1202', 'prdL2-1201', 'prdL2-1132', 'prdL2-1423', 'prdL2-0912', 'prdL2-1587', 'prdL2-1131', 'prdL2-1206']\n"
     ]
    }
   ],
   "source": [
    "def create_item_cooccurrence_matrix(interactions):\n",
    "    \n",
    "    cooccurrence_matrix = interactions.T.dot(interactions).toarray()\n",
    "    np.fill_diagonal(cooccurrence_matrix, 0)  # 0 to avoid self-interaction\n",
    "    return cooccurrence_matrix\n",
    "\n",
    "cooccurrence_matrix = create_item_cooccurrence_matrix(x)\n",
    "\n",
    "def get_item_recommendations(item_id, cooccurrence_matrix, item_dict, top_k=10):\n",
    "    \n",
    "    item_cooccurrences = cooccurrence_matrix[:, item_id] # extracting the co-interactions for the item\n",
    "    top_items = np.argsort(-item_cooccurrences)[:top_k] # find the top items with the most co-interactions\n",
    "    \n",
    "    recommended_items = [item_dict[item] for item in top_items] # translating the item-iDs \n",
    "    return recommended_items\n",
    "\n",
    "recommended_items = get_item_recommendations(2, cooccurrence_matrix, product_L2s_dict, top_k=10)\n",
    "\n",
    "print(\"Recommended items for this purchase:\", recommended_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-cooling",
   "metadata": {},
   "source": [
    "This is a basic approach, but it does the job. However, methods such as ARM and ALS are likely to perform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-russian",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
